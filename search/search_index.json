{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The main objective of this part two is to learn how to build our image, to run our application/service. Two paths are discussed: Building images interactively Create a container from a base image. Install software manually in the container, and turn it into a new image. Learn about new commands: docker commit, docker tag, and docker diff. Building docker images with Dockerfiles Basic \"instructions\": a quick overview. Write a Dockerfile. details on CMD/ENTRIPOINT/COPY Build an image from a Dockerfile. A Python App example Extra: multi-stage","title":"Home"},{"location":"cacheimaegs/cache-dangling/","text":"Let's do a quick check on our docker system: docker images REPOSITORY TAG IMAGE ID CREATED SIZE test latest 259e2e6b1ac1 7 minutes ago 101MB <none> <none> 589c6427b137 7 minutes ago 101MB ubuntu 18.04 81bcf752ac3d 3 weeks ago 63.1MB gcr.io/k8s-minikube/kicbase v0.0.22 bcd131522525 5 weeks ago 1.09GB we should wonder what are the images with a <none> tag, you can see when you list all the images present on your system Tip Spolinig: these are dagnling images One thing more: docker images -a REPOSITORY TAG IMAGE ID CREATED SIZE test latest 259e2e6b1ac1 7 minutes ago 101MB <none> <none> 589c6427b137 7 minutes ago 101MB <none> <none> e63fa5024b8d 7 minutes ago 101MB <none> <none> 24a0ae7fb9f2 7 minutes ago 101MB <none> <none> 333abd901bf3 7 minutes ago 99.7MB ubuntu 18.04 81bcf752ac3d 3 weeks ago 63.1MB gcr.io/k8s-minikube/kicbase v0.0.22 bcd131522525 5 weeks ago 1.09GB again: why there are these images with a <none> tag, you can see when you list all the images present on your system Tip Spolinig: these are intermediate cached images Let's clean-up all our docker environment and use our previusly developed Dockerfile to package the application docker system prune Be carefull! this wil clean-up a lot: all stopped containers all networks not used by at least one container all dangling images all dangling build cache there are other way to select what to remove see here [REF] Tip docker rmi $(docker images -a --filter=dangling=true -q) docker rm $(docker ps --filter=status=exited --filter=status=created -q) once we have cleaned our system we will get something like the following: $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE gcr.io/k8s-minikube/kicbase v0.0.22 bcd131522525 5 weeks ago 1.09GB ubuntu latest 7e0aa2d69a15 7 weeks ago 72.7MB $ docker images -a REPOSITORY TAG IMAGE ID CREATED SIZE gcr.io/k8s-minikube/kicbase v0.0.22 bcd131522525 5 weeks ago 1.09GB ubuntu latest 7e0aa2d69a15 7 weeks ago 72.7MB tutor5@tutorvm-5:~/myimage$ this is time now to build our application. So let's start again with our Dockerfile: FROM ubuntu:18.04 RUN apt-get update RUN apt-get install -y figlet ENTRYPOINT [\"figlet\", \"-f\", \"script\"] CMD [\"pippo\"] Now we can build it and we will get something like this: docker build -t testnone . Sending build context to Docker daemon 2.048kB Step 1/5 : FROM ubuntu:18.04 18.04: Pulling from library/ubuntu 4bbfd2c87b75: Pull complete d2e110be24e1: Pull complete 889a7173dcfe: Pull complete Digest: sha256:67b730ece0d34429b455c08124ffd444f021b81e06fa2d9cd0adaf0d0b875182 Status: Downloaded newer image for ubuntu:18.04 ---> 81bcf752ac3d Step 2/5 : RUN apt-get update ---> Running in 80bb3a4b5a8c ... ( remove output ) Reading package lists... Removing intermediate container 80bb3a4b5a8c ---> e095319ffe18 Step 3/5 : RUN apt-get install figlet ---> Running in 30b20940a069 .... ( remove output ) Removing intermediate container 30b20940a069 ---> 9ad1cce70073 Step 4/5 : ENTRYPOINT [\"figlet\", \"-f\", \"script\"] ---> Running in 911a64ae9765 Removing intermediate container 911a64ae9765 ---> cca054892aec Step 5/5 : CMD [\"pippo\"] ---> Running in 67d507ed70c0 Removing intermediate container 67d507ed70c0 ---> f0684153d22f Successfully built f0684153d22f Successfully tagged testnone:latest and let's check again our system: tutor5@tutorvm-5:~/myimage$ docker images REPOSITORY TAG IMAGE ID CREATED SIZE testnone latest f0684153d22f About a minute ago 101MB ubuntu 18.04 81bcf752ac3d 3 weeks ago 63.1MB gcr.io/k8s-minikube/kicbase v0.0.22 bcd131522525 5 weeks ago 1.09GB ubuntu latest 7e0aa2d69a15 7 weeks ago 72.7MB alright but then if I check further: tutor5@tutorvm-5:~/myimage$ docker images -a REPOSITORY TAG IMAGE ID CREATED SIZE testnone latest f0684153d22f About a minute ago 101MB <none> <none> cca054892aec About a minute ago 101MB <none> <none> 9ad1cce70073 About a minute ago 101MB <none> <none> e095319ffe18 2 minutes ago 99.7MB ubuntu 18.04 81bcf752ac3d 3 weeks ago 63.1MB gcr.io/k8s-minikube/kicbase v0.0.22 bcd131522525 5 weeks ago 1.09GB ubuntu latest 7e0aa2d69a15 7 weeks ago 72.7MB where those come from ? Those are the intermediate images genereated while building our image: Removing intermediate container 80bb3a4b5a8c ---> e095319ffe18 Step 3/5 : RUN apt-get install figlet ---> Running in 30b20940a069 .... ( remove output ) Removing intermediate container 30b20940a069 ---> 9ad1cce70073 Step 4/5 : ENTRYPOINT [\"figlet\", \"-f\", \"script\"] ---> Running in 911a64ae9765 Removing intermediate container 911a64ae9765 ---> cca054892aec a container is run changes corresponding to the instruction defined in the step are done inside of this container the container is committed into an image (that is an intermediate image) that will be used as the base image of the next step Now the last step.. let's change our build starting from the previous Dockerfile and changing it: FROM ubuntu:18.04 RUN apt-get update RUN apt-get install -y figlet ENTRYPOINT [ \"figlet\" , \"-f\" , \"script\" ] CMD [ \"ciccio\" ] <---- build it as we did before: docker build -t testnone . Sending build context to Docker daemon 2.048kB Step 1/5 : FROM ubuntu:18.04 ---> 81bcf752ac3d Step 2/5 : RUN apt-get update ---> Using cache ---> e095319ffe18 Step 3/5 : RUN apt-get install figlet ---> Using cache ---> 9ad1cce70073 Step 4/5 : ENTRYPOINT [\"figlet\", \"-f\", \"script\"] ---> Using cache ---> cca054892aec Step 5/5 : CMD [\"Ciccio\"] ---> Running in 976759d6217c Removing intermediate container 976759d6217c ---> 3624cff02928 Successfully built 3624cff02928 Successfully tagged testnone:latest and now check again your images.. docker images REPOSITORY TAG IMAGE ID CREATED SIZE testnone latest 3624cff02928 4 seconds ago 101MB <none> <none> f0684153d22f 17 minutes ago 101MB ubuntu 18.04 81bcf752ac3d 3 weeks ago 63.1MB gcr.io/k8s-minikube/kicbase v0.0.22 bcd131522525 5 weeks ago 1.09GB ubuntu latest 7e0aa2d69a15 7 weeks ago 72.7MB Now, this IMAGE ID f0684153d22f is not more linked to the image named testnone cause the second build has set it on the newly created image (the one containing the changes we did in Dockerfile) The previous image, now considered as dangling, is not referenced anymore. We can remove it, but we probably first need to make sure we have not used the same tag in the second build by mistake (that happens :) ) If needed, you can tag again the dandling image any other image ( we saw it previously ) Finally, in order to check ( and possibly remove ) the dangling images you can play with something like this: docker images -a --filter = dangling = true","title":"... or what are those nasty <none> tags"},{"location":"dockerfile/cmd-entrypoint/","text":"CMD and ENTRYPOINT are the commands that allow us to set the default command to run in a container. Adding CMD to our Dockerfile \u00b6 As example: we want to se a nice hello message, and using a custom font in our docker container, for that reason we will execute: figlet -f script hello Tip -f script tells figlet to use a fancy font. hello is the message that we want it to display. Let's modify our Dockerfile to support this default: FROM ubuntu RUN apt-get update RUN apt-get install -y figlet CMD figlet -f script hello and let's build it again : docker build -t myfiglet . This time you will see the effect of the cache and the output is the following: Sending build context to Docker daemon 2.048kB Step 1/4 : FROM ubuntu:18.04 ---> 81bcf752ac3d Step 2/4 : RUN apt-get update ---> Using cache ---> e2ed94338e24 Step 3/4 : RUN apt-get install figlet ---> Using cache ---> d9c8c229f154 Step 4/4 : CMD figlet -f script hello ---> Running in a9f4bc819ea7 Removing intermediate container a9f4bc819ea7 ---> e14a6ebfbd5e Successfully built e14a6ebfbd5e Successfully tagged myfiglet:latest Run it: docker run -ti myfiglet The output will looks like the following: _ _ _ | | | | | | | | _ | | | | __ |/ \\ |/ |/ |/ / \\_ | |_/|__/|__/|__/\\__/ Overriding CMD \u00b6 If we want to get a shell into our container (instead of running figlet), we just have to specify a different program to run. If we aspecify bash , it will replace the value of CMD . Try it: docker run -it myfiglet bash Using ENTRYPOINT \u00b6 And what about if We want to be able to specify a different message on the command line, while retaining figlet and some default parameters? Example: we would like to be able to do this: docker run myfiglet Good Morning We will use the ENTRYPOINT verb in Dockerfile FROM ubuntu RUN apt-get update RUN apt-get install -y figlet ENTRYPOINT [ \"figlet\" , \"-f\" , \"script\" ] Tip ENTRYPOINT defines a base command (and its parameters) for the container. The command line arguments are appended to those parameters. Like CMD, ENTRYPOINT can appear anywhere, and replaces the previous value. When CMD or ENTRYPOINT use string syntax, they get wrapped in sh -c and it would run the following command in the figlet image: sh -c \"figlet -f script\" salut To avoid this wrapping, we can use JSON syntax. Let's build and test: docker build -t myfiglet . and run: docker run myfiglet pippo o _ _ _ __ |/ \\_| |/ \\_|/ \\_/ \\_ |__/ |_/|__/ |__/ \\__/ /| /| /| \\| \\| \\| If we want to run a shell in our container, We cannot just do docker run myfiglet bash because that would just tell figlet to display the word \"bash.\" We use the --entrypoint parameter: $ docker run -it --entrypoint bash myfiglet root@6027e44e2955:/# Combine CMD and ENTRYPOINT \u00b6 What if we want to define a default message for our container? Then we will use ENTRYPOINT and CMD together. ENTRYPOINT will define the base command for our container. CMD will define the default parameter(s) for this command. They both have to use JSON syntax. ENTRYPOINT defines a base command (and its parameters) for the container. If we don't specify extra command-line arguments when starting the container, the value of CMD is appended. Otherwise, our extra command-line arguments are used instead of CMD. FROM ubuntu:18.04 RUN apt-get update RUN apt-get install -y figlet ENTRYPOINT [ \"figlet\" , \"-f\" , \"script\" ] CMD [ \"ciccio\" ] Tip Finally CMD and ENTRYPOINT recap - docker run myimage executes ENTRYPOINT + CMD - docker run myimage args executes ENTRYPOINT + args (overriding CMD) - docker run --entrypoint prog myimage executes prog (overriding both)","title":"The CMD and ENTRYPOINT verbs"},{"location":"dockerfile/cmd-entrypoint/#adding-cmd-to-our-dockerfile","text":"As example: we want to se a nice hello message, and using a custom font in our docker container, for that reason we will execute: figlet -f script hello Tip -f script tells figlet to use a fancy font. hello is the message that we want it to display. Let's modify our Dockerfile to support this default: FROM ubuntu RUN apt-get update RUN apt-get install -y figlet CMD figlet -f script hello and let's build it again : docker build -t myfiglet . This time you will see the effect of the cache and the output is the following: Sending build context to Docker daemon 2.048kB Step 1/4 : FROM ubuntu:18.04 ---> 81bcf752ac3d Step 2/4 : RUN apt-get update ---> Using cache ---> e2ed94338e24 Step 3/4 : RUN apt-get install figlet ---> Using cache ---> d9c8c229f154 Step 4/4 : CMD figlet -f script hello ---> Running in a9f4bc819ea7 Removing intermediate container a9f4bc819ea7 ---> e14a6ebfbd5e Successfully built e14a6ebfbd5e Successfully tagged myfiglet:latest Run it: docker run -ti myfiglet The output will looks like the following: _ _ _ | | | | | | | | _ | | | | __ |/ \\ |/ |/ |/ / \\_ | |_/|__/|__/|__/\\__/","title":"Adding CMD to our Dockerfile"},{"location":"dockerfile/cmd-entrypoint/#overriding-cmd","text":"If we want to get a shell into our container (instead of running figlet), we just have to specify a different program to run. If we aspecify bash , it will replace the value of CMD . Try it: docker run -it myfiglet bash","title":"Overriding CMD"},{"location":"dockerfile/cmd-entrypoint/#using-entrypoint","text":"And what about if We want to be able to specify a different message on the command line, while retaining figlet and some default parameters? Example: we would like to be able to do this: docker run myfiglet Good Morning We will use the ENTRYPOINT verb in Dockerfile FROM ubuntu RUN apt-get update RUN apt-get install -y figlet ENTRYPOINT [ \"figlet\" , \"-f\" , \"script\" ] Tip ENTRYPOINT defines a base command (and its parameters) for the container. The command line arguments are appended to those parameters. Like CMD, ENTRYPOINT can appear anywhere, and replaces the previous value. When CMD or ENTRYPOINT use string syntax, they get wrapped in sh -c and it would run the following command in the figlet image: sh -c \"figlet -f script\" salut To avoid this wrapping, we can use JSON syntax. Let's build and test: docker build -t myfiglet . and run: docker run myfiglet pippo o _ _ _ __ |/ \\_| |/ \\_|/ \\_/ \\_ |__/ |_/|__/ |__/ \\__/ /| /| /| \\| \\| \\| If we want to run a shell in our container, We cannot just do docker run myfiglet bash because that would just tell figlet to display the word \"bash.\" We use the --entrypoint parameter: $ docker run -it --entrypoint bash myfiglet root@6027e44e2955:/#","title":"Using ENTRYPOINT"},{"location":"dockerfile/cmd-entrypoint/#combine-cmd-and-entrypoint","text":"What if we want to define a default message for our container? Then we will use ENTRYPOINT and CMD together. ENTRYPOINT will define the base command for our container. CMD will define the default parameter(s) for this command. They both have to use JSON syntax. ENTRYPOINT defines a base command (and its parameters) for the container. If we don't specify extra command-line arguments when starting the container, the value of CMD is appended. Otherwise, our extra command-line arguments are used instead of CMD. FROM ubuntu:18.04 RUN apt-get update RUN apt-get install -y figlet ENTRYPOINT [ \"figlet\" , \"-f\" , \"script\" ] CMD [ \"ciccio\" ] Tip Finally CMD and ENTRYPOINT recap - docker run myimage executes ENTRYPOINT + CMD - docker run myimage args executes ENTRYPOINT + args (overriding CMD) - docker run --entrypoint prog myimage executes prog (overriding both)","title":"Combine CMD and ENTRYPOINT"},{"location":"dockerfile/copy/","text":"This section is about another Dockerfile keyword: COPY . During the previous sections we have installed things in our container images by downloading packages. In the real life we might also do something slightly different such as: copy files from the build context to the container that we are building. Tip Remember: the build context is the directory containing the Dockerfile. Build some C code \u00b6 In the following simple example we want to build a container that compiles a basic \"Hello world\" program in C. Example, a hello.c: int main () { puts ( \"Hello, world!\" ); return 0 ; } We can create a new directory, and put this file in there. Then we will write the Dockerfile and we will use COPY to place the source file into the container Tip On Debian and Ubuntu, the package build-essential will get us a compiler. When installing it, don't forget to specify the -y flag, otherwise the build will fail (since the build cannot be interactive). FROM ubuntu RUN apt-get update RUN apt-get install -y build-essential COPY hello.c / RUN make hello CMD /hello Exercise: Create hello.c and Dockerfile in the same directory: Run docker build -t hello . in this directory. Run docker run hello, you should see Hello, world!. COPY and the build cache \u00b6 Docker can cache steps involving COPY. Those steps will not be executed again if the files haven't been changed. You can try it yourself by - Run the build again, but now modify hello.c The .dockerignore file \u00b6 Something you need to take care of is to avoid copy of unneeded files i.e. files in your context but not required in the image. To do that you have a handle: .dockerignore You can create it at the top-level of the build context specifying file names and globs to ignore They won't be sent to the builder and won't end up in the resulting image See the documentation for the little details","title":"Copying files during the build"},{"location":"dockerfile/copy/#build-some-c-code","text":"In the following simple example we want to build a container that compiles a basic \"Hello world\" program in C. Example, a hello.c: int main () { puts ( \"Hello, world!\" ); return 0 ; } We can create a new directory, and put this file in there. Then we will write the Dockerfile and we will use COPY to place the source file into the container Tip On Debian and Ubuntu, the package build-essential will get us a compiler. When installing it, don't forget to specify the -y flag, otherwise the build will fail (since the build cannot be interactive). FROM ubuntu RUN apt-get update RUN apt-get install -y build-essential COPY hello.c / RUN make hello CMD /hello Exercise: Create hello.c and Dockerfile in the same directory: Run docker build -t hello . in this directory. Run docker run hello, you should see Hello, world!.","title":"Build some C code"},{"location":"dockerfile/copy/#copy-and-the-build-cache","text":"Docker can cache steps involving COPY. Those steps will not be executed again if the files haven't been changed. You can try it yourself by - Run the build again, but now modify hello.c","title":"COPY and the build cache"},{"location":"dockerfile/copy/#the-dockerignore-file","text":"Something you need to take care of is to avoid copy of unneeded files i.e. files in your context but not required in the image. To do that you have a handle: .dockerignore You can create it at the top-level of the build context specifying file names and globs to ignore They won't be sent to the builder and won't end up in the resulting image See the documentation for the little details","title":"The .dockerignore file"},{"location":"dockerfile/exercise/","text":"The main objective of the exercise is to add a Dockerfile to a Python App. So we have an application and we are asked to do the following: * we need to create a Dockerfile that runs our python application and expose on a well defined port, let's say the 9000. On that port the app will return the environment variable ENVIRONMENT=production ( unless we will ask to return something different ) Tip You can get the files needed to complete the exercise either from git git clone https://github.com/spigad/simple-exercise.git or just cut&paste the code here below. The App \u00b6 A simple python3 API that only responds at / . It returns the value of the ENVIRONMENT environment var as JSON. from flask import Flask import os import sys app = Flask ( __name__ ) @app . route ( \"/\" ) def index (): env = os . getenv ( \"ENVIRONMENT\" , None ) return { \"env\" : env } if __name__ == \"__main__\" : if len ( sys . argv ) < 2 : print ( \"Needs port number as a commandline argument.\" ) sys . exit ( 1 ) port = int ( sys . argv [ 1 ]) app . run ( host = '0.0.0.0' , port = port ) The Dependencies \u00b6 Our App has some dependences, so we need to take care of them, here below the list of the software dependences: Click==7.0 Flask==1.1.1 itsdangerous==1.1.0 Jinja2==2.11.3 MarkupSafe==1.1.1 Werkzeug==0.16.0 Tip We will Use pip to install the requirements listed in requirements.txt : * pip install -r requirements.txt Running the server \u00b6 Of course we want our App be up&running. The server requires one command line argument: the port that it should listen on. To run the app we need just something like python app.py <PORT> Compose the Dockerfile \u00b6 Let's now build the Dockerfile in order to pack our app FROM python:3.7-slim-buster RUN apt-get update && apt-get install -y curl COPY requirements.txt /tmp/ RUN pip install -r /tmp/requirements.txt ENV PORT = \"3000\" EXPOSE ${PORT} RUN useradd --create-home pythonappuser WORKDIR /home/pythonappuser COPY startup.sh . COPY app.py . RUN chmod +x startup.sh && chmod +x app.py && chown -R pythonappuser:pythonappuser . USER pythonappuser ENTRYPOINT [ \"./startup.sh\" ] Now we can try to build it: docker build -t mycontainerizedapp . Playing with our Dockerized - App \u00b6 First of all let's check it is doing what is expected. So we should run the container and check that the Python App is actually running. So docker run -d mycontainerizedapp now we can get the ID of the container ( you know how to do that now ) and then we can get a bash in to our container: docker exec -ti 9ea45699221b bash Now if it is correctly running it should tell us something if we ask someting on its port 3000 ( remmember what we set in our Dockerfile above ) pythonappuser@9ea45699221b:~$ curl localhost:3000 { \"env\" : \"prod\" } pythonappuser@9ea45699221b:~$ here we go!! it works nicely. Very good, let's do a step further. We know that we can map the exposed port to the HOST.. so let's do it docker run -d -p 3000 :3000 mycontainerizedapp if it is all working now I shouldn't need to enter the container to check the status of the App on port 3000.. let's try curl localhost:3000 { \"env\" : \"prod\" } It works. So all is ok. Tip Remember that the EXPOSE instruction does not actually publish the port. It functions as a type of documentation between the person who builds the image and the person who runs the container, about which ports are intended to be published Final step now is about the env variable. Can we re-define it when we startup the continer ? yes we can, remember the -e docker run -d -p 3000 :3000 -e ENVIRONMENT = ciccio mycontainerizedapp If it worked correctly we should get something different wrt the previous test by querying the port 3000.. let's try: curl localhost:3000 { \"env\" : \"ciccio\" } ineed! All good! Optimize the building ( simple example ) \u00b6 Now, provided that you got the repo: git clone https://github.com/spigad/simple-exercise.git you can try to optimize a bit and use the .dockerignore file. So, you should create the file with the following content: *.md .git* and then you can check the effect of the .dockerignore by comaparing the Sending build context to Docker daemon with and without.","title":"Exercise"},{"location":"dockerfile/exercise/#the-app","text":"A simple python3 API that only responds at / . It returns the value of the ENVIRONMENT environment var as JSON. from flask import Flask import os import sys app = Flask ( __name__ ) @app . route ( \"/\" ) def index (): env = os . getenv ( \"ENVIRONMENT\" , None ) return { \"env\" : env } if __name__ == \"__main__\" : if len ( sys . argv ) < 2 : print ( \"Needs port number as a commandline argument.\" ) sys . exit ( 1 ) port = int ( sys . argv [ 1 ]) app . run ( host = '0.0.0.0' , port = port )","title":"The App"},{"location":"dockerfile/exercise/#the-dependencies","text":"Our App has some dependences, so we need to take care of them, here below the list of the software dependences: Click==7.0 Flask==1.1.1 itsdangerous==1.1.0 Jinja2==2.11.3 MarkupSafe==1.1.1 Werkzeug==0.16.0 Tip We will Use pip to install the requirements listed in requirements.txt : * pip install -r requirements.txt","title":"The  Dependencies"},{"location":"dockerfile/exercise/#running-the-server","text":"Of course we want our App be up&running. The server requires one command line argument: the port that it should listen on. To run the app we need just something like python app.py <PORT>","title":"Running the server"},{"location":"dockerfile/exercise/#compose-the-dockerfile","text":"Let's now build the Dockerfile in order to pack our app FROM python:3.7-slim-buster RUN apt-get update && apt-get install -y curl COPY requirements.txt /tmp/ RUN pip install -r /tmp/requirements.txt ENV PORT = \"3000\" EXPOSE ${PORT} RUN useradd --create-home pythonappuser WORKDIR /home/pythonappuser COPY startup.sh . COPY app.py . RUN chmod +x startup.sh && chmod +x app.py && chown -R pythonappuser:pythonappuser . USER pythonappuser ENTRYPOINT [ \"./startup.sh\" ] Now we can try to build it: docker build -t mycontainerizedapp .","title":"Compose the Dockerfile"},{"location":"dockerfile/exercise/#playing-with-our-dockerized-app","text":"First of all let's check it is doing what is expected. So we should run the container and check that the Python App is actually running. So docker run -d mycontainerizedapp now we can get the ID of the container ( you know how to do that now ) and then we can get a bash in to our container: docker exec -ti 9ea45699221b bash Now if it is correctly running it should tell us something if we ask someting on its port 3000 ( remmember what we set in our Dockerfile above ) pythonappuser@9ea45699221b:~$ curl localhost:3000 { \"env\" : \"prod\" } pythonappuser@9ea45699221b:~$ here we go!! it works nicely. Very good, let's do a step further. We know that we can map the exposed port to the HOST.. so let's do it docker run -d -p 3000 :3000 mycontainerizedapp if it is all working now I shouldn't need to enter the container to check the status of the App on port 3000.. let's try curl localhost:3000 { \"env\" : \"prod\" } It works. So all is ok. Tip Remember that the EXPOSE instruction does not actually publish the port. It functions as a type of documentation between the person who builds the image and the person who runs the container, about which ports are intended to be published Final step now is about the env variable. Can we re-define it when we startup the continer ? yes we can, remember the -e docker run -d -p 3000 :3000 -e ENVIRONMENT = ciccio mycontainerizedapp If it worked correctly we should get something different wrt the previous test by querying the port 3000.. let's try: curl localhost:3000 { \"env\" : \"ciccio\" } ineed! All good!","title":"Playing with our Dockerized - App"},{"location":"dockerfile/exercise/#optimize-the-building-simple-example","text":"Now, provided that you got the repo: git clone https://github.com/spigad/simple-exercise.git you can try to optimize a bit and use the .dockerignore file. So, you should create the file with the following content: *.md .git* and then you can check the effect of the .dockerignore by comaparing the Sending build context to Docker daemon with and without.","title":"Optimize the building ( simple example )"},{"location":"dockerfile/first-dockerfile/","text":"A Dockerfile is a build recipe for a Docker image. It contains a series of instructions telling Docker how an image is constructed. Our first Dockerfile \u00b6 Our Dockerfile must be in a new, empty directory so first step is to create a directory to hold our Dockerfile. Command mkdir myimage and now create a Dockerfile inside this directory. Command cd myimage vim Dockerfile (feel fre to choose any editor you like) and add the follwing content: FROM ubuntu:18.04 RUN apt-get update RUN apt-get install -y figlet Tip FROM indicates the base image for our build. Each RUN line will be executed by Docker during the build. RUN commands must be non-interactive. (No input can be provided to Docker during the build.) this is why we add the -y flag to apt-get. Every Dockerfile must start with the FROM instruction. The idea behind is that you need a starting point to build your image. You can start FROM scratch , scratch is an explicitly empty image on the Docker store that is used to build base images such as Alpine a lightweight linux distro that allows you to reduce the overall size of Docker images. Save our file, then execute: Command docker build -t myfiglet . Tip -t indicates the tag to apply to the image. . indicates the location of the build context. The output you will get is something like the follwing Sending build context to Docker daemon 2.048kB Step 1/3 : FROM ubuntu:18.04 ---> 81bcf752ac3d Step 2/3 : RUN apt-get update ---> Running in 9f07f31f5608 ...(..cut RUN output..)... Reading package lists... Removing intermediate container 9f07f31f5608 ---> e2ed94338e24 Step 3/3 : RUN apt-get install figlet ---> Running in 9548f425acac Reading package lists... ...(..cut RUN output..)... Removing intermediate container 9548f425acac ---> d9c8c229f154 Successfully built d9c8c229f154 Successfully tagged myfiglet:latest Let's analyze the oputput: Sending build context to Docker daemon 2.048 kB The build context is the . directory given to docker build. It is sent (as an archive) by the Docker client to the Docker daemon. This allows to use a remote machine to build using local files. Be careful (or patient) if that directory is big and your link is slow. You can speed up the process with a .dockerignore file which tells docker to ignore specific files in the directory, ignore files that you won't need in the build context! Step 2/3 : RUN apt-get update ---> Running in 9f07f31f5608 ...(..cut RUN output..)... Reading package lists... Removing intermediate container 9f07f31f5608 ---> e2ed94338e24 A container (9f07f31f5608) is created from the base image. The RUN command is executed in this container. The container is committed into an image (e2ed94338e24). The build container (9f07f31f5608) is removed. The output of this step will be the base image for the next one. Tip After each build step, Docker takes a snapshot of the resulting image and before executing a step, Docker checks if it has already built the same sequence. Docker uses the exact strings defined in your Dockerfile, so the following two are not the same! RUN apt-get install figlet cowsay RUN apt-get install cowsay figlet You can force a rebuild with docker build --no-cache .... And to close the loop: (only) RUN , COPY and ADD instructions create layers to improve build performance. The main advantage of image layering lies in image caching. Running the image \u00b6 The resulting image is not different from the one produced manually. :) docker run -ti myfiglet bash and issue something like: root@4d7d8ec44135:/# figlet ciao ciao _ _ ___(_) __ _ ___ ___(_) __ _ ___ / __| |/ _` |/ _ \\ / __| |/ _` |/ _ \\ | (__| | (_| | (_) | | (__| | (_| | (_) | \\___|_|\\__,_|\\___/ \\___|_|\\__,_|\\___/ root@4d7d8ec44135:/#","title":"Write the first Dockerfile"},{"location":"dockerfile/first-dockerfile/#our-first-dockerfile","text":"Our Dockerfile must be in a new, empty directory so first step is to create a directory to hold our Dockerfile. Command mkdir myimage and now create a Dockerfile inside this directory. Command cd myimage vim Dockerfile (feel fre to choose any editor you like) and add the follwing content: FROM ubuntu:18.04 RUN apt-get update RUN apt-get install -y figlet Tip FROM indicates the base image for our build. Each RUN line will be executed by Docker during the build. RUN commands must be non-interactive. (No input can be provided to Docker during the build.) this is why we add the -y flag to apt-get. Every Dockerfile must start with the FROM instruction. The idea behind is that you need a starting point to build your image. You can start FROM scratch , scratch is an explicitly empty image on the Docker store that is used to build base images such as Alpine a lightweight linux distro that allows you to reduce the overall size of Docker images. Save our file, then execute: Command docker build -t myfiglet . Tip -t indicates the tag to apply to the image. . indicates the location of the build context. The output you will get is something like the follwing Sending build context to Docker daemon 2.048kB Step 1/3 : FROM ubuntu:18.04 ---> 81bcf752ac3d Step 2/3 : RUN apt-get update ---> Running in 9f07f31f5608 ...(..cut RUN output..)... Reading package lists... Removing intermediate container 9f07f31f5608 ---> e2ed94338e24 Step 3/3 : RUN apt-get install figlet ---> Running in 9548f425acac Reading package lists... ...(..cut RUN output..)... Removing intermediate container 9548f425acac ---> d9c8c229f154 Successfully built d9c8c229f154 Successfully tagged myfiglet:latest Let's analyze the oputput: Sending build context to Docker daemon 2.048 kB The build context is the . directory given to docker build. It is sent (as an archive) by the Docker client to the Docker daemon. This allows to use a remote machine to build using local files. Be careful (or patient) if that directory is big and your link is slow. You can speed up the process with a .dockerignore file which tells docker to ignore specific files in the directory, ignore files that you won't need in the build context! Step 2/3 : RUN apt-get update ---> Running in 9f07f31f5608 ...(..cut RUN output..)... Reading package lists... Removing intermediate container 9f07f31f5608 ---> e2ed94338e24 A container (9f07f31f5608) is created from the base image. The RUN command is executed in this container. The container is committed into an image (e2ed94338e24). The build container (9f07f31f5608) is removed. The output of this step will be the base image for the next one. Tip After each build step, Docker takes a snapshot of the resulting image and before executing a step, Docker checks if it has already built the same sequence. Docker uses the exact strings defined in your Dockerfile, so the following two are not the same! RUN apt-get install figlet cowsay RUN apt-get install cowsay figlet You can force a rebuild with docker build --no-cache .... And to close the loop: (only) RUN , COPY and ADD instructions create layers to improve build performance. The main advantage of image layering lies in image caching.","title":"Our first Dockerfile"},{"location":"dockerfile/first-dockerfile/#running-the-image","text":"The resulting image is not different from the one produced manually. :) docker run -ti myfiglet bash and issue something like: root@4d7d8ec44135:/# figlet ciao ciao _ _ ___(_) __ _ ___ ___(_) __ _ ___ / __| |/ _` |/ _ \\ / __| |/ _` |/ _ \\ | (__| | (_| | (_) | | (__| | (_| | (_) | \\___|_|\\__,_|\\___/ \\___|_|\\__,_|\\___/ root@4d7d8ec44135:/#","title":"Running the image"},{"location":"dockerfile/instructions/","text":"We\u2019ll cover the following basic instructions to get you started: FROM - every Dockerfile starts with FROM, with the introduction of multi-stage builds, you can have more than one FROM instruction in one Dockerfile. COPY vs ADD - Add directories and files to your Docker image. ( Sometime confuesd... ) ENV - set environment variables. RUN - let\u2019s run commands. USER - when root is too mainstream. WORKDIR - set the working directory. EXPOSE - get your ports right. FROM \u00b6 Every Dockerfile must start with the FROM instruction in the form of FROM <image>[:tag] . This will set the base image for your Dockerfile, which means that subsequent instructions will be applied to this base image. The tag value is optional , if you don\u2019t specify the tag Docker will use the tag latest and will try and use or pull the latest version of the base image during build. On the little bit more advanced side, let\u2019s note the following: There is one instruction that you can put before FROM into your Dockerfile. This instruction is ARG . ARG is used to specify arguments for the docker build command with the --build-arg <varname>=<value> flag. You can have more than one FROM instructions in your Dockerfile. You will want to use this feature, for example, when you use one base image to build your app and another base image to run it. It\u2019s called a multi-stage build and you can read about it here . This is why every section that starts with FROM in your Dockerfile is called a build stage (even in the simple case of having only one FROM instruction). You can specify the name of the build stage in the form FROM <image>[:tag] [AS <name>] . COPY vs ADD \u00b6 Both ADD and COPY are designed to add directories and files to your Docker image in the form of ADD <src>... <dest> or COPY <src>... <dest> . Most resources, suggest to use COPY . The reason behind this is that ADD has extra features compared to COPY that make ADD more unpredictable and a bit over-designed. ADD can pull files from url sources, which COPY cannot. ADD can also extract compressed files assuming it can recognize and handle the format. You cannot extract archives with COPY. The ADD instruction was added to Docker first, and COPY was added later to provide a straightforward, rock solid solution for copying files and directories into your container\u2019s file system. If you want to pull files from the web into your image I would suggest to use RUN and curl and uncompress your files with RUN and commands you would use on the command line. ENV \u00b6 ENV is used to define environment variables. The interesting thing about ENV is that it does two things: You can use it to define environment variables that will be available in your container. So when you build an image and start up a container with that image you\u2019ll find that the environment variable is available and is set to the value you specified in the Dockerfile. You can use the variables that you specify by ENV in the Dockerfile itself. So in subsequent instructions the environment variable will be available. RUN \u00b6 RUN will execute commands, so it\u2019s one of the most-used instructions. I would like to highlight two points: You\u2019ll use a lot of apt-get type of commands to add new packages to your image. It\u2019s always advisable to put apt-get update and apt-get install commands on the same line . This is important because of layer caching. Having these on two separate lines would mean that if you add a new package to your install list, the layer with apt-get update will not be invalidated in the layer cache and you might end up in a mess. Read more here. RUN has two forms; RUN <command> (called shell form) and RUN [\"executable\", \"param1\", \"param2\"] called exec form. Please note that RUN <command> will invoke a shell automatically (/bin/sh -c by default), while the exec form will not invoke a command shell. USER \u00b6 Don\u2019t run your stuff as root, use the USER instruction to specify the user. This user will be used to run any subsequent RUN, CMD AND ENDPOINT instructions in your Dockerfile. WORKDIR \u00b6 A very convenient way to define the working directory, it will be used with subsequent RUN, CMD, ENTRYPOINT, COPY and ADD instructions. You can specify WORKDIR multiple times in a Dockerfile. If the directory does not exists, Docker will create it for you. EXPOSE \u00b6 An important instruction to inform your users about the ports your application is listening on. EXPOSE will not publish the port , you need to use docker run -p... to do that when you start the container. CMD and ENTRYPOINT \u00b6 CMD is the instruction to specify what component is to be run by your image with arguments in the following form: CMD [\u201cexecutable\u201d, \u201cparam1\u201d, \u201cparam2\u201d\u2026]. You can override CMD when you\u2019re starting up your container by specifying your command after the image name like this: $ docker run [OPTIONS] IMAGE[:TAG|@DIGEST] [COMMAND] [ARG...] . You can only specify one CMD in a Dockerfile (OK, physically you can specify more than one, but only the last one will be used). So what\u2019s the deal with ENTRYPOINT? When you specify an entry point, your image will work a bit differently. You use ENTRYPOINT as the main executable of your image . In this case whatever you specify in CMD will be added to ENTRYPOINT as parameters.","title":"Overview of basic instructions"},{"location":"dockerfile/instructions/#from","text":"Every Dockerfile must start with the FROM instruction in the form of FROM <image>[:tag] . This will set the base image for your Dockerfile, which means that subsequent instructions will be applied to this base image. The tag value is optional , if you don\u2019t specify the tag Docker will use the tag latest and will try and use or pull the latest version of the base image during build. On the little bit more advanced side, let\u2019s note the following: There is one instruction that you can put before FROM into your Dockerfile. This instruction is ARG . ARG is used to specify arguments for the docker build command with the --build-arg <varname>=<value> flag. You can have more than one FROM instructions in your Dockerfile. You will want to use this feature, for example, when you use one base image to build your app and another base image to run it. It\u2019s called a multi-stage build and you can read about it here . This is why every section that starts with FROM in your Dockerfile is called a build stage (even in the simple case of having only one FROM instruction). You can specify the name of the build stage in the form FROM <image>[:tag] [AS <name>] .","title":"FROM"},{"location":"dockerfile/instructions/#copy-vs-add","text":"Both ADD and COPY are designed to add directories and files to your Docker image in the form of ADD <src>... <dest> or COPY <src>... <dest> . Most resources, suggest to use COPY . The reason behind this is that ADD has extra features compared to COPY that make ADD more unpredictable and a bit over-designed. ADD can pull files from url sources, which COPY cannot. ADD can also extract compressed files assuming it can recognize and handle the format. You cannot extract archives with COPY. The ADD instruction was added to Docker first, and COPY was added later to provide a straightforward, rock solid solution for copying files and directories into your container\u2019s file system. If you want to pull files from the web into your image I would suggest to use RUN and curl and uncompress your files with RUN and commands you would use on the command line.","title":"COPY vs ADD"},{"location":"dockerfile/instructions/#env","text":"ENV is used to define environment variables. The interesting thing about ENV is that it does two things: You can use it to define environment variables that will be available in your container. So when you build an image and start up a container with that image you\u2019ll find that the environment variable is available and is set to the value you specified in the Dockerfile. You can use the variables that you specify by ENV in the Dockerfile itself. So in subsequent instructions the environment variable will be available.","title":"ENV"},{"location":"dockerfile/instructions/#run","text":"RUN will execute commands, so it\u2019s one of the most-used instructions. I would like to highlight two points: You\u2019ll use a lot of apt-get type of commands to add new packages to your image. It\u2019s always advisable to put apt-get update and apt-get install commands on the same line . This is important because of layer caching. Having these on two separate lines would mean that if you add a new package to your install list, the layer with apt-get update will not be invalidated in the layer cache and you might end up in a mess. Read more here. RUN has two forms; RUN <command> (called shell form) and RUN [\"executable\", \"param1\", \"param2\"] called exec form. Please note that RUN <command> will invoke a shell automatically (/bin/sh -c by default), while the exec form will not invoke a command shell.","title":"RUN"},{"location":"dockerfile/instructions/#user","text":"Don\u2019t run your stuff as root, use the USER instruction to specify the user. This user will be used to run any subsequent RUN, CMD AND ENDPOINT instructions in your Dockerfile.","title":"USER"},{"location":"dockerfile/instructions/#workdir","text":"A very convenient way to define the working directory, it will be used with subsequent RUN, CMD, ENTRYPOINT, COPY and ADD instructions. You can specify WORKDIR multiple times in a Dockerfile. If the directory does not exists, Docker will create it for you.","title":"WORKDIR"},{"location":"dockerfile/instructions/#expose","text":"An important instruction to inform your users about the ports your application is listening on. EXPOSE will not publish the port , you need to use docker run -p... to do that when you start the container.","title":"EXPOSE"},{"location":"dockerfile/instructions/#cmd-and-entrypoint","text":"CMD is the instruction to specify what component is to be run by your image with arguments in the following form: CMD [\u201cexecutable\u201d, \u201cparam1\u201d, \u201cparam2\u201d\u2026]. You can override CMD when you\u2019re starting up your container by specifying your command after the image name like this: $ docker run [OPTIONS] IMAGE[:TAG|@DIGEST] [COMMAND] [ARG...] . You can only specify one CMD in a Dockerfile (OK, physically you can specify more than one, but only the last one will be used). So what\u2019s the deal with ENTRYPOINT? When you specify an entry point, your image will work a bit differently. You use ENTRYPOINT as the main executable of your image . In this case whatever you specify in CMD will be added to ENTRYPOINT as parameters.","title":"CMD and ENTRYPOINT"},{"location":"intro/","text":"This is a quick recap of things that you already saw in the Part-1. The following steps guide you toward the interactive image building process. Getting an image and apply some changes \u00b6 Command docker run -it ubuntu:18.04 You will get something like the following output: Unable to find image 'ubuntu:18.04' locally 18.04: Pulling from library/ubuntu 4bbfd2c87b75: Pull complete d2e110be24e1: Pull complete 889a7173dcfe: Pull complete Digest: sha256:67b730ece0d34429b455c08124ffd444f021b81e06fa2d9cd0adaf0d0b875182 Status: Downloaded newer image for ubuntu:18.04 root@844ec9e540a5:/# Run the command apt-get update to refresh the list of packages available to install. For this simple exercise we will use Figlet Then run the command apt-get install figlet to install the program we are interested in. Command apt-get update && apt-get install figlet You will get something like the following output: root@844ec9e540a5:/# apt-get update && apt-get install figlet Get:1 http://archive.ubuntu.com/ubuntu bionic InRelease [242 kB] Get:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] Get:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB] Get:4 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 Packages [1344 kB] Get:6 http://archive.ubuntu.com/ubuntu bionic/restricted amd64 Packages [13.5 kB] Get:7 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 Packages [186 kB] Get:8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 Packages [11.3 MB] Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [33.5 kB] Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [481 kB] Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2619 kB] Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2185 kB] Get:13 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [11.4 kB] Get:14 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [11.3 kB] Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1415 kB] ... ... Check the differences with respect to the original image \u00b6 Once done type exit at the container prompt to leave the interactive session. Now let's run docker diff to see the difference between the base image and our container. Command docker diff 844ec9e540a5 Tip Remember: you need to use your container ID. In order to get it you can always use docker ps -a and the output you will get is something like C /root A /root/.bash_history C /etc A /etc/emacs A /etc/emacs/site-start.d A /etc/emacs/site-start.d/50figlet.el C /etc/alternatives A /etc/alternatives/figlet C /usr C /usr/share A /usr/share/figlet A /usr/share/figlet/646-ca.flc A /usr/share/figlet/646-ca2.flc A /usr/share/figlet/646-hu.flc Tip Three different types of change are tracked by docker diff : - A A file or directory was added - D A file or directory was deleted - C A file or directory was changed Commit the changes and use your image \u00b6 The last step is now to commit the changes, that way we will create a new layer with the changes we made before, and a new image using this new layer. Command docker commit 844ec9e540a5 interactivefiglet Here we go! we have build our first image interactively! Let's run it and test it Command docker run -ti interactivefiglet once you entered the container you can type something like the following: Command figlet ciao ciao you will get your expected output: _ _ ___(_) __ _ ___ ___(_) __ _ ___ / __| |/ _` |/ _ \\ / __| |/ _` |/ _ \\ | (__| | (_| | (_) | | (__| | (_| | (_) | \\___|_|\\__,_|\\___/ \\___|_|\\__,_|\\___/ root@be9e5e08db21:/# This is ok for quick & dirty test and playground .. but what about if we need to be reproducible, automated ? To this end we need to learn the build process by writing a Dockerfile.","title":"Building images interactively"},{"location":"intro/#getting-an-image-and-apply-some-changes","text":"Command docker run -it ubuntu:18.04 You will get something like the following output: Unable to find image 'ubuntu:18.04' locally 18.04: Pulling from library/ubuntu 4bbfd2c87b75: Pull complete d2e110be24e1: Pull complete 889a7173dcfe: Pull complete Digest: sha256:67b730ece0d34429b455c08124ffd444f021b81e06fa2d9cd0adaf0d0b875182 Status: Downloaded newer image for ubuntu:18.04 root@844ec9e540a5:/# Run the command apt-get update to refresh the list of packages available to install. For this simple exercise we will use Figlet Then run the command apt-get install figlet to install the program we are interested in. Command apt-get update && apt-get install figlet You will get something like the following output: root@844ec9e540a5:/# apt-get update && apt-get install figlet Get:1 http://archive.ubuntu.com/ubuntu bionic InRelease [242 kB] Get:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] Get:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB] Get:4 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 Packages [1344 kB] Get:6 http://archive.ubuntu.com/ubuntu bionic/restricted amd64 Packages [13.5 kB] Get:7 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 Packages [186 kB] Get:8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 Packages [11.3 MB] Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [33.5 kB] Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [481 kB] Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2619 kB] Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2185 kB] Get:13 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [11.4 kB] Get:14 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [11.3 kB] Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1415 kB] ... ...","title":"Getting an image and apply some changes"},{"location":"intro/#check-the-differences-with-respect-to-the-original-image","text":"Once done type exit at the container prompt to leave the interactive session. Now let's run docker diff to see the difference between the base image and our container. Command docker diff 844ec9e540a5 Tip Remember: you need to use your container ID. In order to get it you can always use docker ps -a and the output you will get is something like C /root A /root/.bash_history C /etc A /etc/emacs A /etc/emacs/site-start.d A /etc/emacs/site-start.d/50figlet.el C /etc/alternatives A /etc/alternatives/figlet C /usr C /usr/share A /usr/share/figlet A /usr/share/figlet/646-ca.flc A /usr/share/figlet/646-ca2.flc A /usr/share/figlet/646-hu.flc Tip Three different types of change are tracked by docker diff : - A A file or directory was added - D A file or directory was deleted - C A file or directory was changed","title":"Check the differences with respect to the original image"},{"location":"intro/#commit-the-changes-and-use-your-image","text":"The last step is now to commit the changes, that way we will create a new layer with the changes we made before, and a new image using this new layer. Command docker commit 844ec9e540a5 interactivefiglet Here we go! we have build our first image interactively! Let's run it and test it Command docker run -ti interactivefiglet once you entered the container you can type something like the following: Command figlet ciao ciao you will get your expected output: _ _ ___(_) __ _ ___ ___(_) __ _ ___ / __| |/ _` |/ _ \\ / __| |/ _` |/ _ \\ | (__| | (_| | (_) | | (__| | (_| | (_) | \\___|_|\\__,_|\\___/ \\___|_|\\__,_|\\___/ root@be9e5e08db21:/# This is ok for quick & dirty test and playground .. but what about if we need to be reproducible, automated ? To this end we need to learn the build process by writing a Dockerfile.","title":"Commit the changes and use your image"},{"location":"multistage/multistage-example/","text":"The objective here is to try to use multi-stage images in practice. To this end we will change our Dockerfile to: give a nickname to the first stage: compiler add a second stage using the same ubuntu base image add the hello binary to the second stage make sure that CMD is in the second stage Mulit-stage Docker file: example \u00b6 Here is the final Dockerfile: FROM ubuntu AS compiler RUN apt-get update RUN apt-get install -y build-essential COPY hello.c / RUN make hello FROM ubuntu COPY --from = compiler /hello /hello CMD /hello Let's build it, and check that it works correctly: docker build -t hellomultistage . and now we can test: docker run hellomultistage Home work \u00b6 List our images with docker images, and check the size of: The ubuntu base image, The single-stage hello image, The multi-stage hellomultistage image. We can achieve even smaller images if we use smaller base images ( i.e. Apline etc )","title":"Our first multi-stage Dockerfile"},{"location":"multistage/multistage-example/#mulit-stage-docker-file-example","text":"Here is the final Dockerfile: FROM ubuntu AS compiler RUN apt-get update RUN apt-get install -y build-essential COPY hello.c / RUN make hello FROM ubuntu COPY --from = compiler /hello /hello CMD /hello Let's build it, and check that it works correctly: docker build -t hellomultistage . and now we can test: docker run hellomultistage","title":"Mulit-stage Docker file: example"},{"location":"multistage/multistage-example/#home-work","text":"List our images with docker images, and check the size of: The ubuntu base image, The single-stage hello image, The multi-stage hellomultistage image. We can achieve even smaller images if we use smaller base images ( i.e. Apline etc )","title":"Home work"},{"location":"registry/dockerhub/","text":"Now that we have built our first images, we can publish them to the Docker Hub! Logging into our Docker Hub account \u00b6 docker login This requires an account on the Docker Hub ( which is free as well as storing the images it is free ). So if you have one you can try a thus you'll see a output like this: Login with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one. Username: spiga Password: WARNING! Your password will be stored unencrypted in /home/tutor5/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded Tagging an image to push it on the Hub \u00b6 Docker images tags are like Git tags and branches, like bookmarks pointing at a specific image ID. Tagging an image doesn't rename an image: it adds another tag. When pushing an image to a registry, the registry address is in the tag. Example: registry.example.net:5000/image spiga/test is index.docker.io/spiga/test ubuntu is index.docker.io/library/ubuntu Let's tag our myfiglet image \u00b6 Or please do it with any other image you like. Let's look for the image to tag: $docker images REPOSITORY TAG IMAGE ID CREATED SIZE myfiglet latest cabcb70593be 15 seconds ago 103MB mycontainerizedapp latest b64faab26e8f 30 hours ago 147MB python 3.7-slim-buster 867339bd5033 2 weeks ago 113MB ubuntu 18.04 81bcf752ac3d 3 weeks ago 63.1MB gcr.io/k8s-minikube/kicbase v0.0.22 bcd131522525 5 weeks ago 1.09GB ubuntu latest 7e0aa2d69a15 7 weeks ago 72.7MB Ok let's tag the myfiglet docker tag myfiglet spiga/myfiglet and check what's happening now: docker images REPOSITORY TAG IMAGE ID CREATED SIZE myfiglet latest cabcb70593be About a minute ago 103MB spiga/myfiglet latest cabcb70593be About a minute ago 103MB mycontainerizedapp latest b64faab26e8f 30 hours ago 147MB python 3.7-slim-buster 867339bd5033 2 weeks ago 113MB ubuntu 18.04 81bcf752ac3d 3 weeks ago 63.1MB gcr.io/k8s-minikube/kicbase v0.0.22 bcd131522525 5 weeks ago 1.09GB ubuntu latest 7e0aa2d69a15 7 weeks ago 72.7MB Ok so we are ready to push it on Dockerhub docker push spiga/myfiglet and the output will look like something this one Using default tag: latest The push refers to repository [docker.io/spiga/myfiglet] f0f9028d0afb: Pushed 3ee587de5e03: Pushed 2f140462f3bc: Mounted from library/ubuntu 63c99163f472: Mounted from library/ubuntu ccdbb80308cc: Mounted from library/ubuntu latest: digest: sha256:ec988085cd4d5efa6bdb5b26a3694eff2c6e26032521c4b6cb248b4efb0f5f51 size: 1365 Ok, very good! That's it! Anybody can now docker run spiga/myfiglet anywhere . Quick check \u00b6 Now if we remove the image on local filesystem and the we get it back from the registry ( DockerHub ) we can see how it works and we close the loop. Tip To remove the image : docker rmi IMAGE ID . To get the IMAGE ID just use docker images docker pull spiga/myfiglet Using default tag: latest latest: Pulling from spiga/myfiglet 345e3491a907: Already exists 57671312ef6f: Already exists 5e9250ddb7d0: Already exists d9dac9d5417f: Pull complete bdf8f857644c: Pull complete Digest: sha256:ec988085cd4d5efa6bdb5b26a3694eff2c6e26032521c4b6cb248b4efb0f5f51 Status: Downloaded newer image for spiga/myfiglet:latest docker.io/spiga/myfiglet:latest","title":"Publishing images to the Docker hub"},{"location":"registry/dockerhub/#logging-into-our-docker-hub-account","text":"docker login This requires an account on the Docker Hub ( which is free as well as storing the images it is free ). So if you have one you can try a thus you'll see a output like this: Login with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one. Username: spiga Password: WARNING! Your password will be stored unencrypted in /home/tutor5/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded","title":"Logging into our Docker Hub account"},{"location":"registry/dockerhub/#tagging-an-image-to-push-it-on-the-hub","text":"Docker images tags are like Git tags and branches, like bookmarks pointing at a specific image ID. Tagging an image doesn't rename an image: it adds another tag. When pushing an image to a registry, the registry address is in the tag. Example: registry.example.net:5000/image spiga/test is index.docker.io/spiga/test ubuntu is index.docker.io/library/ubuntu","title":"Tagging an image to push it on the Hub"},{"location":"registry/dockerhub/#lets-tag-our-myfiglet-image","text":"Or please do it with any other image you like. Let's look for the image to tag: $docker images REPOSITORY TAG IMAGE ID CREATED SIZE myfiglet latest cabcb70593be 15 seconds ago 103MB mycontainerizedapp latest b64faab26e8f 30 hours ago 147MB python 3.7-slim-buster 867339bd5033 2 weeks ago 113MB ubuntu 18.04 81bcf752ac3d 3 weeks ago 63.1MB gcr.io/k8s-minikube/kicbase v0.0.22 bcd131522525 5 weeks ago 1.09GB ubuntu latest 7e0aa2d69a15 7 weeks ago 72.7MB Ok let's tag the myfiglet docker tag myfiglet spiga/myfiglet and check what's happening now: docker images REPOSITORY TAG IMAGE ID CREATED SIZE myfiglet latest cabcb70593be About a minute ago 103MB spiga/myfiglet latest cabcb70593be About a minute ago 103MB mycontainerizedapp latest b64faab26e8f 30 hours ago 147MB python 3.7-slim-buster 867339bd5033 2 weeks ago 113MB ubuntu 18.04 81bcf752ac3d 3 weeks ago 63.1MB gcr.io/k8s-minikube/kicbase v0.0.22 bcd131522525 5 weeks ago 1.09GB ubuntu latest 7e0aa2d69a15 7 weeks ago 72.7MB Ok so we are ready to push it on Dockerhub docker push spiga/myfiglet and the output will look like something this one Using default tag: latest The push refers to repository [docker.io/spiga/myfiglet] f0f9028d0afb: Pushed 3ee587de5e03: Pushed 2f140462f3bc: Mounted from library/ubuntu 63c99163f472: Mounted from library/ubuntu ccdbb80308cc: Mounted from library/ubuntu latest: digest: sha256:ec988085cd4d5efa6bdb5b26a3694eff2c6e26032521c4b6cb248b4efb0f5f51 size: 1365 Ok, very good! That's it! Anybody can now docker run spiga/myfiglet anywhere .","title":"Let's tag our myfiglet image"},{"location":"registry/dockerhub/#quick-check","text":"Now if we remove the image on local filesystem and the we get it back from the registry ( DockerHub ) we can see how it works and we close the loop. Tip To remove the image : docker rmi IMAGE ID . To get the IMAGE ID just use docker images docker pull spiga/myfiglet Using default tag: latest latest: Pulling from spiga/myfiglet 345e3491a907: Already exists 57671312ef6f: Already exists 5e9250ddb7d0: Already exists d9dac9d5417f: Pull complete bdf8f857644c: Pull complete Digest: sha256:ec988085cd4d5efa6bdb5b26a3694eff2c6e26032521c4b6cb248b4efb0f5f51 Status: Downloaded newer image for spiga/myfiglet:latest docker.io/spiga/myfiglet:latest","title":"Quick check"}]}